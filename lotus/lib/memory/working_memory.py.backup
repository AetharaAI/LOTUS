"""
LOTUS Memory System - L1: Working Memory

Ultra-fast Redis-backed working memory for immediate context.
This is the "RAM" of LOTUS's memory system.

Characteristics:
- TTL: 10 minutes (configurable)
- Storage: Redis (in-memory, fast)
- Capacity: ~100 items
- Search: Keyword-based
- Use case: Current conversation context

This tier stores EVERYTHING initially, then lets items expire or
get promoted to L2 based on importance and access patterns.
"""

import json
import time
from typing import List, Dict, Any, Optional
import redis.asyncio as redis

from .base import MemoryTier, MemoryItem, MemoryType


class WorkingMemory(MemoryTier):
    """
    L1: Working Memory - Immediate context (last 10 minutes)
    
    This is where ALL memories land first. Think of it as LOTUS's
    immediate awareness - what's happening right now.
    
    Storage:
    - Redis keys: `working:{memory_id}`
    - Redis list: `working:timeline` (ordered by recency)
    - TTL: 600 seconds (10 minutes) by default
    
    When working memory items expire, they're automatically moved to
    L2 (Short-term) by the consolidation process if they're important.
    """
    
    def __init__(self, redis_client: redis.Redis, 
                 ttl_seconds: int = 600, max_items: int = 100):
        """
        Initialize Working Memory
        
        Args:
            redis_client: Async Redis client
            ttl_seconds: Time-to-live for memories (default: 10 min)
            max_items: Maximum items to keep in working memory
        """
        super().__init__("working_memory", tier_level=1, ttl=ttl_seconds)
        self.redis = redis_client
        self.max_items = max_items
        
        # Key prefixes
        self.key_prefix = "lotus:memory:L1:"
        self.timeline_key = f"{self.key_prefix}timeline"
    
    async def store(self, memory: MemoryItem) -> str:
        """
        Store memory in L1 (Working Memory)
        
        Process:
        1. Serialize memory to JSON
        2. Store in Redis with TTL
        3. Add to timeline list
        4. Enforce max_items limit
        """
        # Set source tier
        memory.source_tier = "L1"
        
        # Generate memory key
        memory_key = f"{self.key_prefix}{memory.id}"
        
        # Serialize memory
        memory_data = json.dumps(memory.to_dict())
        
        # Store with TTL
        await self.redis.setex(memory_key, self.ttl, memory_data)
        
        # Add to timeline (most recent first)
        await self.redis.lpush(self.timeline_key, memory.id)
        
        # Trim timeline to max_items
        await self.redis.ltrim(self.timeline_key, 0, self.max_items - 1)
        
        return memory.id
    
    async def retrieve(self, query: str, limit: int = 10,
                      filters: Optional[Dict] = None) -> List[MemoryItem]:
        """
        Retrieve memories from working memory
        
        Search method:
        - If query is "*" or empty: return all recent memories
        - Otherwise: keyword search in content
        
        Returns most recent memories first
        """
        memories = []
        
        # Get recent memory IDs from timeline
        memory_ids = await self.redis.lrange(self.timeline_key, 0, self.max_items - 1)
        
        for memory_id_bytes in memory_ids:
            memory_id = memory_id_bytes.decode('utf-8')
            memory_key = f"{self.key_prefix}{memory_id}"
            
            # Get memory data
            memory_data = await self.redis.get(memory_key)
            
            if not memory_data:
                # Memory expired, remove from timeline
                await self.redis.lrem(self.timeline_key, 0, memory_id)
                continue
            
            # Deserialize
            mem_dict = json.loads(memory_data)
            memory = MemoryItem.from_dict(mem_dict)
            
            # Apply filters
            if filters:
                if 'memory_type' in filters:
                    if memory.memory_type.value != filters['memory_type']:
                        continue
                
                if 'min_importance' in filters:
                    if memory.importance < filters['min_importance']:
                        continue
            
            # Search query
            if query and query != "*":
                query_lower = query.lower()
                if query_lower not in memory.content.lower():
                    continue
            
            # Mark as accessed
            memory.mark_accessed()
            
            # Update access tracking in Redis
            await self.redis.setex(memory_key, self.ttl, json.dumps(memory.to_dict()))
            
            memories.append(memory)
            
            if len(memories) >= limit:
                break
        
        return memories
    
    async def delete(self, memory_id: str) -> bool:
        """Delete a specific memory from working memory"""
        memory_key = f"{self.key_prefix}{memory_id}"
        
        # Delete from Redis
        deleted = await self.redis.delete(memory_key)
        
        # Remove from timeline
        await self.redis.lrem(self.timeline_key, 0, memory_id)
        
        return deleted > 0
    
    async def get_stats(self) -> Dict[str, Any]:
        """Get working memory statistics"""
        # Get timeline length
        timeline_length = await self.redis.llen(self.timeline_key)
        
        # Get all memory IDs
        memory_ids = await self.redis.lrange(self.timeline_key, 0, -1)
        
        # Calculate stats
        total_memories = 0
        total_importance = 0.0
        oldest_timestamp = None
        newest_timestamp = None
        memory_types = {}
        
        for memory_id_bytes in memory_ids:
            memory_id = memory_id_bytes.decode('utf-8')
            memory_key = f"{self.key_prefix}{memory_id}"
            memory_data = await self.redis.get(memory_key)
            
            if memory_data:
                total_memories += 1
                mem_dict = json.loads(memory_data)
                
                total_importance += mem_dict['importance']
                
                timestamp = mem_dict['timestamp']
                if oldest_timestamp is None or timestamp < oldest_timestamp:
                    oldest_timestamp = timestamp
                if newest_timestamp is None or timestamp > newest_timestamp:
                    newest_timestamp = timestamp
                
                mem_type = mem_dict['memory_type']
                memory_types[mem_type] = memory_types.get(mem_type, 0) + 1
        
        return {
            "tier": "L1_working",
            "count": total_memories,
            "max_capacity": self.max_items,
            "utilization": total_memories / self.max_items if self.max_items > 0 else 0,
            "avg_importance": total_importance / total_memories if total_memories > 0 else 0,
            "oldest_timestamp": oldest_timestamp,
            "newest_timestamp": newest_timestamp,
            "age_minutes": (time.time() - oldest_timestamp) / 60 if oldest_timestamp else 0,
            "memory_types": memory_types,
            "ttl_seconds": self.ttl
        }
    
    async def get_all_for_consolidation(self) -> List[MemoryItem]:
        """
        Get all memories for consolidation process
        
        Returns memories that should be considered for promotion to L2
        """
        return await self.retrieve("*", limit=self.max_items)
    
    async def clear(self) -> int:
        """
        Clear all working memory (use with caution!)
        
        Returns:
            Number of memories cleared
        """
        # Get all memory IDs
        memory_ids = await self.redis.lrange(self.timeline_key, 0, -1)
        
        count = 0
        for memory_id_bytes in memory_ids:
            memory_id = memory_id_bytes.decode('utf-8')
            if await self.delete(memory_id):
                count += 1
        
        # Clear timeline
        await self.redis.delete(self.timeline_key)
        
        return count
    
    async def health_check(self) -> bool:
        """Check if Redis is accessible"""
        try:
            await self.redis.ping()
            self.is_healthy = True
            return True
        except Exception as e:
            self.is_healthy = False
            return False
    
    def should_store_in_tier(self, memory: MemoryItem) -> bool:
        """
        Working memory stores EVERYTHING initially
        
        All memories pass through L1 first
        """
        return True
    
    async def get_recent_context(self, minutes: int = 10) -> List[MemoryItem]:
        """
        Get all memories from the last N minutes
        
        This is used to build conversation context for the reasoning engine
        
        Args:
            minutes: How far back to look
            
        Returns:
            List of recent memories, newest first
        """
        cutoff_time = time.time() - (minutes * 60)
        
        all_memories = await self.retrieve("*", limit=self.max_items)
        
        recent = [m for m in all_memories if m.timestamp >= cutoff_time]
        
        # Sort by timestamp, newest first
        recent.sort(key=lambda m: m.timestamp, reverse=True)
        
        return recent